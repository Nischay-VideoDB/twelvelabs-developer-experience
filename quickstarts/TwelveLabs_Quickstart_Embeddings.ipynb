{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYwIL79-xXQJ"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/twelvelabs-io/twelvelabs-developer-experience/blob/main/quickstarts/TwelveLabs_Quickstart_Embeddings.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in  Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmpYRcFNT30r"
   },
   "source": [
    "# Create embeddings\n",
    "\n",
    "This guide shows how to utilize the TwelveLabs Python SDK to create embeddings for your videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "Before you begin, ensure the following prerequisites are met:\n",
    "\n",
    "- [Sign up](https://playground.twelvelabs.io/) for a free account and obtain your API key from the [API Key](https://playground.twelvelabs.io/dashboard/api-key) page. No credit card is required to use the Free plan. This plan allows you to index up to 600 minutes of videos, which is sufficient for a small project. \n",
    "- The videos you wish to upload must meet the requirements int the [Prerequisites](https://docs.twelvelabs.io/v1.3/docs/guides/create-embeddings/video/new#prerequisites) section of the **Create video embeddings** page.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the TwelveLabs Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q twelvelabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab, store your API key as a Secret named `TL_API_KEY`. If you don't know how to create a Colab Secret, see https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75.\n",
    "\n",
    "from google.colab import userdata\n",
    "TL_API_KEY = userdata.get('TL_API_KEY')\n",
    "\n",
    "# For other Python environments, you can use environment variables\n",
    "# TL_API_KEY = os.environ.get('TL_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhXzSOCgUdmv"
   },
   "source": [
    "## **Generate Embeddings**\n",
    "Use the Embed API to create multimodal embeddings that are contextual vector representations for your videos and texts. Twelve Labs video embeddings capture all the subtle cues and interactions between different modalities, including the visual expressions, body language, spoken words, and the overall context of the video, encapsulating the essence of all these modalities and their interrelations over time.\n",
    "\n",
    "To create video embeddings, you must first upload your videos, and the platform must finish processing them. Uploading and processing videos require some time. Consequently, creating embeddings is an asynchronous process comprised of three steps:\n",
    "\n",
    "1. Upload and process a video: When you start uploading a video, the platform creates a video embedding task and returns its unique task identifier.\n",
    "\n",
    "2. Monitor the status of your video embedding task: Use the unique identifier of your task to check its status periodically until it's completed.\n",
    "\n",
    "3. Retrieve the embeddings: After the video embedding task is completed, retrieve the video embeddings by providing the task identifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elAj0cm1Upaa",
    "outputId": "3592ee9f-7037-4025-b201-45c93e5e901a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created task: id=67c8408ad4e0d626915c1a32 model_name=Marengo-retrieval-2.7 status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=processing\n",
      "  Status=ready\n",
      "Embedding done: ready\n",
      "  embedding_scope=clip start_offset_sec=0.0 end_offset_sec=6.0\n",
      "  embeddings: [0.0025792755, 0.014416745, 0.013344925, -0.023667203, -0.034136135]\n",
      "  embedding_scope=clip start_offset_sec=6.0 end_offset_sec=12.0\n",
      "  embeddings: [0.014718804, 0.0048405766, 0.021370944, -0.029890832, -0.02597869]\n"
     ]
    }
   ],
   "source": [
    "from twelvelabs import TwelveLabs\n",
    "from typing import List\n",
    "from twelvelabs.models.embed import EmbeddingsTask, SegmentEmbedding\n",
    "\n",
    "def print_segments(segments: List[SegmentEmbedding], max_elements: int = 5):\n",
    "    for segment in segments:\n",
    "        print(\n",
    "            f\"  embedding_scope={segment.embedding_scope} embedding_option={segment.embedding_option} start_offset_sec={segment.start_offset_sec} end_offset_sec={segment.end_offset_sec}\"\n",
    "        )\n",
    "        print(f\"  embeddings: {segment.embeddings_float[:max_elements]}\")\n",
    "\n",
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "task = client.embed.task.create(\n",
    "    model_name=\"Marengo-retrieval-2.7\",\n",
    "    video_url=\"https://sample-videos.com/video321/mp4/720/big_buck_bunny_720p_2mb.mp4\" # # Example: https://sample-videos.com/video321/mp4/720/big_buck_bunny_720p_2mb.mp4\n",
    ")\n",
    "print(\n",
    "    f\"Created task: id={task.id} model_name={task.model_name} status={task.status}\"\n",
    ")\n",
    "\n",
    "def on_task_update(task: EmbeddingsTask):\n",
    "    print(f\"  Status={task.status}\")\n",
    "\n",
    "status = task.wait_for_done(\n",
    "    sleep_interval=2,\n",
    "    callback=on_task_update\n",
    ")\n",
    "print(f\"Embedding done: {status}\")\n",
    "\n",
    "task = task.retrieve(embedding_option=[\"visual-text\", \"audio\"])\n",
    "if task.video_embedding is not None and task.video_embedding.segments is not None:\n",
    "    print_segments(task.video_embedding.segments)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
